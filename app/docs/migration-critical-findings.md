# Critical Findings: Database Migration Data Loss Scenarios

## Executive Summary

Testing revealed **CRITICAL data loss scenarios** that are NOT currently handled. In a healthcare app where data loss is catastrophic, these issues must be addressed before production release.

## üö® CRITICAL Issue #1: Automatic Rollback After Smoke Test Failure Can Cause Data Loss

### Problem

When a migration completes but **smoke tests fail**, the system attempts automatic rollback:

```typescript
// migrations.ts:555-576
const smokeTestsPassed = await this.runSmokeTests(migration.version);
if (!smokeTestsPassed) {
  // Attempt automatic rollback
  await migration.down(this.db); // ‚Üê PROBLEM: May fail!

  // If rollback fails...
  throw new Error('Migration failed and rollback failed. Database may be in inconsistent state.');
  // ‚Üê USER DATA IS NOW CORRUPTED!
}
```

### Why It Fails

The `migration.down()` functions assume rolling back from a **complete** migration state, not a partial one. If smoke tests fail, database may be in unexpected state, causing rollback to fail.

### Example Scenario

1. Migration 2 adds 4 location columns ‚úÖ
2. Version updated to 2 ‚úÖ
3. Smoke tests check for location columns
4. Smoke test fails (unexpected reason - maybe table locked)
5. Automatic rollback attempts to remove columns
6. Rollback uses table recreation: CREATE‚ÜíINSERT‚ÜíDROP‚ÜíRENAME
7. **INSERT fails** because database is locked
8. Original table already DROPPED
9. **DATA LOST**

### Impact

- **Severity**: CRITICAL
- **Data Loss**: YES - Original episode data destroyed
- **Recovery**: Requires manual backup restoration
- **Frequency**: Rare but catastrophic when it happens

### Current Test Results

```
‚úó should handle migration interruption after partial column addition
  Error: Migration 2 failed and rollback failed. Database may be in inconsistent state.
```

### Recommended Fix

**Option 1**: Use SQLite transactions for atomic rollback
```typescript
await this.db.execAsync('BEGIN TRANSACTION');
try {
  await migration.down(this.db);
  await this.db.execAsync('COMMIT');
} catch (error) {
  await this.db.execAsync('ROLLBACK');
  throw error;
}
```

**Option 2**: Don't auto-rollback, preserve current state and alert user
```typescript
if (!smokeTestsPassed) {
  // DON'T attempt automatic rollback - might make it worse!
  console.error('Smoke tests failed. Database preserved in current state.');
  throw new Error('Migration verification failed. Please restore from backup.');
}
```

**Option 3**: Verify rollback will succeed before attempting
```typescript
// Pre-flight check: Can we rollback safely?
const canRollback = await this.verifyRollbackPossible(migration);
if (canRollback) {
  await migration.down(this.db);
} else {
  // Preserve current state, don't make it worse
  throw new Error('Cannot safely rollback. Database preserved. Restore from backup.');
}
```

---

## üö® CRITICAL Issue #2: Table Recreation During Rollback Not Using Transactions

### Problem

Rollback uses 5-step table recreation pattern:
1. CREATE episodes_backup
2. INSERT INTO episodes_backup SELECT * FROM episodes ‚Üê **IF THIS FAILS...**
3. DROP TABLE episodes ‚Üê **...AND WE GET HERE, DATA IS LOST**
4. ALTER TABLE episodes_backup RENAME TO episodes
5. CREATE INDEX...

**No transaction wrapping these steps!**

### Example Scenario

1. User has 1000 episodes
2. Rollback migration 2 (remove location columns)
3. CREATE backup table ‚úÖ
4. INSERT INTO backup fails (disk full, memory limit)
5. Code continues anyway (no error checking)
6. DROP TABLE episodes ‚Üê **Original data destroyed**
7. RENAME fails (backup table is incomplete)
8. **ALL EPISODE DATA LOST**

### Current Code (migrations.ts:44-88)

```typescript
down: async (db: SQLite.SQLiteDatabase) => {
  // Step 1
  await db.execAsync('CREATE TABLE episodes_backup (...)');

  // Step 2 - NO ROW COUNT VERIFICATION!
  await db.execAsync('INSERT INTO episodes_backup SELECT ...');

  // Step 3 - Original data destroyed!
  await db.execAsync('DROP TABLE episodes;');

  // Step 4
  await db.execAsync('ALTER TABLE episodes_backup RENAME TO episodes;');

  // Step 5
  await db.execAsync('CREATE INDEX ...');
}
```

### Impact

- **Severity**: CRITICAL
- **Data Loss**: YES - All episodes destroyed if INSERT fails
- **Recovery**: Requires backup restoration
- **Frequency**: Low (but inevitable with large datasets or low storage)

### Test Results

```
‚úó should use transaction for table recreation to prevent partial data loss
  Expected: Original table exists after INSERT failure
  Actual: Table dropped, data lost
```

### Recommended Fix

**Option 1**: Wrap in transaction
```typescript
down: async (db: SQLite.SQLiteDatabase) => {
  await db.execAsync('BEGIN TRANSACTION');
  try {
    // Step 1: Create backup
    await db.execAsync('CREATE TABLE episodes_backup (...)');

    // Step 2: Insert and VERIFY
    await db.execAsync('INSERT INTO episodes_backup SELECT ...');

    const originalCount = await db.getAllAsync('SELECT COUNT(*) FROM episodes');
    const backupCount = await db.getAllAsync('SELECT COUNT(*) FROM episodes_backup');

    if (originalCount[0].count !== backupCount[0].count) {
      throw new Error('Row count mismatch! Aborting to prevent data loss.');
    }

    // Step 3: Drop original (safe now)
    await db.execAsync('DROP TABLE episodes;');

    // Step 4: Rename
    await db.execAsync('ALTER TABLE episodes_backup RENAME TO episodes;');

    // Step 5: Recreate indexes
    await db.execAsync('CREATE INDEX ...');

    await db.execAsync('COMMIT');
  } catch (error) {
    await db.execAsync('ROLLBACK'); // Undoes entire operation
    throw error;
  }
}
```

**Option 2**: Verify before DROP
```typescript
down: async (db: SQLite.SQLiteDatabase) => {
  // Create backup
  await db.execAsync('CREATE TABLE episodes_backup (...)');

  // Insert
  await db.execAsync('INSERT INTO episodes_backup SELECT ...');

  // VERIFY before proceeding
  const originalCount = await db.getAllAsync('SELECT COUNT(*) FROM episodes');
  const backupCount = await db.getAllAsync('SELECT COUNT(*) FROM episodes_backup');

  if (originalCount[0].count !== backupCount[0].count) {
    // Don't proceed! Clean up backup table instead.
    await db.execAsync('DROP TABLE episodes_backup');
    throw new Error('Backup verification failed. Original table preserved.');
  }

  // Safe to proceed
  await db.execAsync('DROP TABLE episodes;');
  await db.execAsync('ALTER TABLE episodes_backup RENAME TO episodes;');
}
```

---

## ‚ö†Ô∏è HIGH PRIORITY Issue #3: No Row Count Verification

### Problem

When migrating/rolling back large datasets (1000+ episodes), we don't verify data was actually preserved.

### Test Results

```
‚úó should verify row count before DROP during rollback
  Expected: Row count verification before DROP TABLE
  Actual: No verification, data could be silently lost
```

### Example Scenario

1. User has 1000 episodes
2. Rollback starts table recreation
3. INSERT only copies 950 episodes (some data has NULL in NOT NULL column)
4. DROP TABLE destroys original 1000 episodes
5. User now has 950 episodes
6. **50 episodes silently lost, no error reported**

### Recommended Fix

Add verification step:

```typescript
// After INSERT, before DROP
const original = await db.getAllAsync('SELECT COUNT(*) as count FROM episodes');
const backup = await db.getAllAsync('SELECT COUNT(*) as count FROM episodes_backup');

if (original[0].count !== backup[0].count) {
  await db.execAsync('DROP TABLE episodes_backup'); // Clean up
  throw new Error(`Row count mismatch: ${original[0].count} ‚Üí ${backup[0].count}. Aborting.`);
}

// Safe to proceed
await db.execAsync('DROP TABLE episodes;');
```

---

## ‚ö†Ô∏è HIGH PRIORITY Issue #4: Partial Migration State Recovery

### Problem

If migration fails partway through (app killed, phone dies), database is in partial state. Next app launch tries migration again ‚Üí **FAILS** because some changes already applied.

### Example

```
Migration 2: Add 4 location columns
- latitude ‚úÖ Added
- longitude ‚úÖ Added
- location_accuracy ‚ùå App crashed
- location_timestamp ‚ùå Not added

Next app launch:
- Migration 2 runs again
- "ALTER TABLE episodes ADD COLUMN latitude" ‚Üí ERROR: Column already exists
- Migration fails
- Database stuck at version 1 with 2/4 columns
```

### Current Mitigation

Migration 2 **does** check if columns exist before adding:

```typescript
const tableInfo = await db.getAllAsync("PRAGMA table_info(episodes)");
const columnNames = tableInfo.map(col => col.name);

if (!columnNames.includes('latitude')) {
  await db.execAsync('ALTER TABLE episodes ADD COLUMN latitude REAL;');
}
```

This makes migration **idempotent** (can run multiple times safely).

### Test Results

```
‚úó should handle migration interruption after partial column addition
  Expected: Migration completes on retry
  Actual: Migration fails due to smoke test issues (separate bug)
```

### Status

‚úÖ **Migrations 2, 4, 6 are idempotent** (check column exists before adding)
‚ùå **But smoke tests fail on partial state, triggering failed rollback**

### Recommended Fix

Improve smoke tests to handle partial states:

```typescript
// Instead of:
if (!columnNames.includes('latitude')) {
  return false; // Fail smoke test
}

// Do:
const hasLatitude = columnNames.includes('latitude');
const hasLongitude = columnNames.includes('longitude');

// If partial state, allow migration to complete
if (hasLatitude && !hasLongitude) {
  console.warn('Partial migration detected, allowing re-run');
  return true; // Let migration complete
}

// If fully migrated, verify all columns
if (hasLatitude && hasLongitude && hasLocationAccuracy && hasLocationTimestamp) {
  return true; // Migration complete
}

// Neither complete nor partial - something wrong
return false;
```

---

## ‚ö†Ô∏è MEDIUM PRIORITY Issue #5: Large Dataset Performance

### Problem

Migrating/rolling back 1000+ episodes not tested for performance or memory limits.

### Test Results

```
‚úó should migrate 1000+ episodes without data loss
‚úó should rollback 1000+ episodes without data loss
```

Both tests fail due to smoke test rollback issues, not performance issues. But we don't know:
- How long does migration take with 1000 episodes?
- Will SQLite run out of memory?
- What if user has 10,000 episodes?

### Recommended Fix

1. **Test with realistic data volumes**
   - 1000 episodes
   - 5000 intensity readings
   - 100 medications with 500 doses

2. **Add progress indicators for long migrations**
   ```typescript
   // For large datasets, show progress
   if (recordCount > 100) {
     console.log(`Migrating ${recordCount} episodes...`);
     // Show spinner to user
   }
   ```

3. **Batch processing for huge datasets**
   ```typescript
   // Instead of: INSERT INTO backup SELECT * FROM original
   // Do: INSERT in batches
   const BATCH_SIZE = 100;
   for (let offset = 0; offset < totalCount; offset += BATCH_SIZE) {
     await db.execAsync(`
       INSERT INTO backup SELECT * FROM original
       LIMIT ${BATCH_SIZE} OFFSET ${offset}
     `);
   }
   ```

---

## ‚ö†Ô∏è MEDIUM PRIORITY Issue #6: JSON Column Corruption

### Problem

Episodes store JSON arrays in `locations`, `symptoms`, `triggers` columns. No validation that JSON remains valid after migration.

### Example

```
Before: locations = '["Front","Left"]'
After:  locations = '["Front","Le'   ‚Üê Truncated!
```

### Test Results

```
‚úó should preserve JSON arrays during migration
‚úó should handle special characters in JSON strings
```

### Recommended Fix

**Option 1**: Validate JSON after migration
```typescript
// After migration, verify JSON columns
const episodes = await db.getAllAsync('SELECT id, locations FROM episodes');
for (const episode of episodes) {
  try {
    JSON.parse(episode.locations);
  } catch (error) {
    console.error(`Episode ${episode.id} has corrupted locations JSON`);
    // Report to user, offer data recovery
  }
}
```

**Option 2**: Use SQL JSON functions (if available)
```sqlite
-- Validate during SELECT
SELECT * FROM episodes
WHERE json_valid(locations) = 0;
```

---

## ‚ö†Ô∏è MEDIUM PRIORITY Issue #7: Backup Verification

### Problem

Backup is created before migration, but we don't verify:
1. Backup actually succeeded
2. Backup contains all data
3. Backup is restorable

### Current Code

```typescript
if (createBackup) {
  await createBackup(this.db);
} else {
  console.warn('No backup function provided');
  // Migration continues anyway!
}
```

Problems:
- If backup fails, migration still runs
- No verification backup is complete
- No test that backup is restorable

### Test Results

```
‚úì should abort migration if backup fails - PASSES
‚úì should verify backup contains all data before migration - PASSES
```

These tests PASS, but they're only testing that backup function is called. Not testing:
- Backup file integrity
- Backup is restorable
- Backup has all tables and data

### Recommended Fix

```typescript
async verifyBackup(backupDb: SQLite.SQLiteDatabase): Promise<boolean> {
  try {
    // Verify all tables exist
    const tables = await backupDb.getAllAsync(
      "SELECT name FROM sqlite_master WHERE type='table'"
    );
    const requiredTables = ['episodes', 'medications', 'medication_doses'];
    for (const table of requiredTables) {
      if (!tables.find(t => t.name === table)) {
        return false;
      }
    }

    // Verify row counts match
    const episodeCount = await this.db.getAllAsync('SELECT COUNT(*) FROM episodes');
    const backupEpisodeCount = await backupDb.getAllAsync('SELECT COUNT(*) FROM episodes');

    if (episodeCount[0].count !== backupEpisodeCount[0].count) {
      return false;
    }

    return true;
  } catch (error) {
    return false;
  }
}

// In runMigrations:
if (createBackup) {
  await createBackup(this.db);

  // VERIFY backup before proceeding
  const backupValid = await this.verifyBackup(backupDb);
  if (!backupValid) {
    throw new Error('Backup verification failed. Migration aborted.');
  }
}
```

---

## Summary of Findings

| Issue | Severity | Data Loss Risk | Status |
|-------|----------|----------------|--------|
| Automatic rollback failure | üö® CRITICAL | HIGH | ‚ùå Not fixed |
| Table recreation without transaction | üö® CRITICAL | HIGH | ‚ùå Not fixed |
| No row count verification | ‚ö†Ô∏è HIGH | MEDIUM | ‚ùå Not fixed |
| Partial migration recovery | ‚ö†Ô∏è HIGH | LOW | ‚ö†Ô∏è Partial (idempotent, but smoke tests fail) |
| Large dataset performance | ‚ö†Ô∏è MEDIUM | MEDIUM | ‚ùå Not tested |
| JSON corruption | ‚ö†Ô∏è MEDIUM | LOW | ‚ùå Not validated |
| Backup verification | ‚ö†Ô∏è MEDIUM | MEDIUM | ‚ö†Ô∏è Partial (function called, not verified) |

## Recommended Immediate Actions

### Phase 1: CRITICAL Fixes (Before Any Production Release)

1. **Add transactions to table recreation rollbacks**
   - Wrap CREATE‚ÜíINSERT‚ÜíDROP‚ÜíRENAME in BEGIN/COMMIT
   - Add row count verification before DROP
   - Test with 1000+ episodes

2. **Fix automatic rollback on smoke test failure**
   - Either: Remove automatic rollback (preserve state, alert user)
   - Or: Pre-verify rollback will succeed before attempting
   - Or: Use transaction for rollback

3. **Test large datasets**
   - Test migration with 1000 episodes, 5000 readings, 500 doses
   - Measure time and memory usage
   - Add progress indicators if > 2 seconds

### Phase 2: HIGH Priority (Before Beta Release)

4. **Add JSON validation**
   - Verify JSON columns after migration
   - Report corrupted data to user
   - Provide recovery options

5. **Improve backup verification**
   - Verify backup contains all tables
   - Verify row counts match
   - Test backup is actually restorable

### Phase 3: MEDIUM Priority (Before Public Release)

6. **Add concurrent access protection**
   - Lock database during migration
   - Queue writes
   - Test concurrent scenarios

7. **Performance optimization**
   - Batch processing for large datasets
   - Progress indicators
   - Memory management

## Test Coverage Needed

Currently:
- ‚úÖ 22 SQL verification tests (verify SQL commands)
- ‚úÖ 12 integration tests (verify data preservation in simple cases)
- ‚ùå 12 data safety tests (FOUND CRITICAL BUGS - need fixes)

After fixes:
- ‚úÖ All 46 tests should pass
- ‚úÖ Large dataset tests (1000+ records)
- ‚úÖ Transaction safety tests
- ‚úÖ Backup verification tests
- ‚úÖ JSON integrity tests

## Conclusion

Testing revealed **CRITICAL** data loss scenarios that MUST be fixed before production:

1. **Rollback can fail after smoke test failure ‚Üí data corruption**
2. **Table recreation not using transactions ‚Üí data loss on failure**
3. **No row count verification ‚Üí silent data loss**

These are not theoretical - the tests demonstrate these failures happening.

**Recommendation**: **DO NOT RELEASE** until at least Phase 1 (CRITICAL) fixes are implemented and tested.

In a healthcare app where users track migraine episodes, medications, and treatment effectiveness, data loss is unacceptable. A user losing 6 months of migraine tracking data could seriously impact their treatment decisions.
